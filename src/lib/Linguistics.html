<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>

  <title></title>

</head><body>
  <div class="article">
    <h2>Description</h2>

    <p>With the Nodebox English Linguistics library you can do grammar inflection and semantic
    operations on English content. You can use the library to conjugate verbs, pluralize nouns,
    write out numbers, find dictionary descriptions and synonyms for words, summarise texts and
    parse grammatical structure from sentences.</p>
    <p>The library bundles <a href="http://www.cogsci.princeton.edu/~wn/">WordNet</a> (using Oliver
    Steele’s <a href="http://osteele.com/projects/pywordnet/">PyWordNet</a>), <a href="http://nltk.sourceforge.net/">NLTK</a>, Damian Conway’s <a href="http://www.csse.monash.edu.au/~damian/papers/HTML/Plurals.html">pluralisation rules</a>, Bermi
    Ferrer’s <a href="http://www.bermi.org/inflector/">singularization rules</a>, Jason Wiener’s
    <a href="http://jasonwiener.wordpress.com/2006/01/20/simple-nlp-part-of-speech-tagger-in-python/">Brill
    tagger</a>, several algorithms adopted from Michael Granger’s <a href="http://www.deveiate.org/projects/Linguistics/wiki/English">Ruby Linguistics</a> module, John
    Wiseman’s implementation of the <a href="http://lemonodor.com/archives/001511.html">Regressive
    Imagery Dictionary</a>, Charles K. Ogden’s list of <a href="http://ogden.basic-english.org">basic English</a> words, and Peter Norvig’s <a href="http://norvig.com/spell-correct.html">spelling corrector</a>.<br/></p>
    <h2>Download</h2>

    <table border="0">
      <tbody>
        <tr>
          <td><a href="http://nodebox.net/code/data/media/linguistics.zip"><img alt="download" height="20" src="../etc/lib/download.gif" width="20"/></a>
          </td><td><a href="http://nodebox.net/code/data/media/linguistics.zip">linguistics.zip</a>
          (15MB)<br/>
          <i>Last updated for PlotDevice 1.9.4.2<br/></i><i>Licensed under GPL<br/>
          Author: Tom De Smedt<br/></i>
        </td></tr></tbody></table>

    <h2>Documentation</h2>

    <ul>
      <li><a href="#loading_the_library">How to get the library up and running</a>
      </li><li><a href="#lexical_categorisation">Categorise words as nouns, verbs, numbers and more</a>
      </li><li><a href="#commonsense">Categorise words as emotional, persuasive or connective<br/></a>
      </li><li><a href="#numbers">Converting between numbers and words</a>
      </li><li><a href="#quantification">Quantification of numbers and lists</a> (e.g. 367 x chicken =
      hundreds of chickens)
      </li><li><a href="#indefinite_article">Indefinite article: a or an</a>
      </li><li><a href="#pluralization">Pluralization/singularization of nouns</a>
      </li><li><a href="#emotional_value">Emotional value of a word</a>
      </li><li><a href="#WordNet">WordNet glossary, synonyms, antonyms, components</a>
      </li><li><a href="#verb_conjugation">Verb conjugation</a>
      </li><li><a href="#spelling">Spelling corrections</a>
      </li><li><a href="#shallow_parsing">Shallow parsing, the grammatical structure of a sentence</a>
      </li><li><a href="#summarisation">Summarisation of text to keywords</a>
      </li><li><a href="#rid">Regressive Imagery Dictionary, content analysis</a>
      </li><li><a href="#ogden">Ogden’s basic English words</a><br/>
    </li></ul>

    <p> </p>
    <hr/>

    <p><a id="loading_the_library" name="loading_the_library" title="loading_the_library"></a></p>
    <h2>How to get the library up and running</h2>

    <p>Put the <i>en</i> library folder in the same folder as your script so PlotDevice can find the
    library. You can also put it in <i>~/Library/Application Support/PlotDevice/.</i> It takes some
    time to load all the data the first time.</p>
<pre>import en
</pre>

    <p> </p>
    <hr/>

    <p><a id="lexical_categorisation" name="lexical_categorisation" title="lexical_categorisation"></a></p>
    <h2>Categorise words as nouns, verbs, numbers and more</h2>

    <p>The <i>is_number()</i> command returns <i>True</i> when the given value is a number:</p>
<pre>print en.is_number(12)
print en.is_number("twelve")
&gt;&gt;&gt; True
&gt;&gt;&gt; True
</pre>

    <p>The <i>is_noun()</i> command returns <i>True</i> when the given string is a noun. You can
    also check for <i>is_verb()</i>, <i>is_adjective()</i> and <i>is_adverb()</i>:</p>
<pre>print en.is_noun("banana")
&gt;&gt;&gt; True
</pre>

    <p>The <i>is_tag()</i> command returns <i>True</i> when the given string is a tag, for example
    HTML or XML.</p>
    <p>The <i>is_html_tag()</i> command returns <i>True</i> when the string is a HTML tag.</p>
    <p> </p>
    <hr/>

    <p><a id="commonsense" name="commonsense" title="commonsense"></a></p>
    <h2>Categorise words as emotional, persuasive or connective</h2>

    <p>The <i>is_basic_emotion()</i> command returns <i>True</i> if the given word expresses a
    basic emotion (anger, disgust, fear, joy, sadness, surprise):</p>
<pre>print en.is_basic_emotion("cheerful")
&gt;&gt;&gt; True
</pre>

    <p>The <i>is_persuasive()</i> command returns <i>True</i> if the given word is a ‘magic’ word
    (you, money, save, new, results, health, easy, ...):</p>
<pre>print en.is_persuasive("money")
&gt;&gt;&gt; True
</pre>

    <p>The <i>is_connective()</i> command returns <i>True</i> if the word is a connective
    (nevertheless, whatever, secondly, ... and words like I, the, own, him which have little
    semantical value):</p>
<pre>print en.is_connective("but")
&gt;&gt;&gt; True
</pre>

    <p> </p>
    <hr/>

    <p><a id="numbers" name="numbers" title="numbers"></a></p>
    <h2>Converting between numbers and words</h2>

    <p>The <i>number.ordinal()</i> command returns the ordinal of the given number, 100 yields
    100th, 3 yields 3rd and twenty-one yields twenty-first:</p>
<pre>print en.number.ordinal(100)
print en.number.ordinal("twenty-one")
&gt;&gt;&gt; 100th
&gt;&gt;&gt; twenty-first
</pre>

    <p>The <i>number.spoken()</i> command writes out the given number:</p>
<pre>print en.number.spoken(25)
&gt;&gt;&gt; twenty-five
</pre>

    <p> </p>
    <hr/>

    <p><a id="quantification" name="quantification" title="quantification"></a></p>
    <h2>Quantification of numbers and lists</h2>

    <p>The <i>number.quantify()</i> command quantifies the given word:</p>
<pre>print en.number.quantify(10, "chicken")
print en.number.quantify(800, "chicken")
&gt;&gt;&gt; a number of chickens
&gt;&gt;&gt; hundreds of chickens
</pre>

    <p>The <i>list.conjunction()</i> command quantifies a list of words. Notice how goose is
    correctly pluralized and duck has the right article.</p>
<pre>farm = ["goose", "goose", "chicken", "chicken", "chicken"]
print en.list.conjunction(farm)
&gt;&gt;&gt; several chickens, a pair of geese and a duck
</pre>

    <p>You can also quantify the types of things in the given list, class or module:</p>
<pre>print en.list.conjunction((1,2,3,4,5), generalize=True)
print en.list.conjunction(en, generalize=True)
&gt;&gt;&gt; several integers
&gt;&gt;&gt; a number of modules, a number of functions, a number of strings, 
&gt;&gt;&gt; a pair of lists, a pair of dictionaries, an en verb, an en sentence, 
&gt;&gt;&gt; an en number, an en noun, an en list, an en content, an en adverb, 
&gt;&gt;&gt; an en adjective, a None type and a plotdevice graphics cocoa Context class
</pre>

    <p> </p>
    <hr/>

    <p><a id="indefinite_article" name="indefinite_article" title="indefinite_article"></a></p>
    <h2>Indefinite article: a or an</h2>

    <p>The <i>noun.article()</i> returns the noun with its indefinite article:</p>
<pre>print en.noun.article("university")
print en.noun.article("owl")
print en.noun.article("hour")
&gt;&gt;&gt; a university
&gt;&gt;&gt; an owl
&gt;&gt;&gt; an hour
</pre>

    <p> </p>
    <hr/>

    <p><a id="pluralization" name="pluralization" title="pluralization"></a></p>
    <h2>Pluralization and singularization of nouns</h2>

    <p>The <i>noun.plural()</i> command pluralizes the given noun:</p>
<pre>print en.noun.plural("child")
print en.noun.plural("kitchen knife")
print en.noun.plural("wolf")
print en.noun.plural("part-of-speech")
&gt;&gt;&gt; children
&gt;&gt;&gt; kitchen knives
&gt;&gt;&gt; wolves
&gt;&gt;&gt; parts-of-speech
</pre>

    <p>You can also do <i>adjective.plural()</i>.</p>
    <p>An optional <i>classical</i> parameter is <i>True</i> by default and determines if either
    classical or modern inflection is used (e.g. classical pluralization of <i>octopus</i> yields
    <i>octopodes</i> instead of <i>octopuses</i>).</p>
    <p>The <i>noun.singular()</i> command singularizes the given plural:</p>
<pre>print en.noun.singular("people")
&gt;&gt;&gt; person
</pre>

    <p> </p>
    <hr/>

    <p><a id="emotional_value" name="emotional_value" title="emotional_value"></a></p>
    <h2>Emotional value of a word</h2>

    <p>The <i>noun.is_emotion()</i> guesses whether the given noun expresses an emotion by checking
    if there are synonyms of the word that are basic emotions. Returns <i>True</i> or <i>False</i>
    by default.</p>
<pre>print en.noun.is_emotion("anger")
&gt;&gt;&gt; True
</pre>

    <p>Or you can return a string which provides some information with the
    <i>boolean</i>=<i>False</i> parameter.</p>
<pre>print en.adjective.is_emotion("anxious", boolean=False)
&gt;&gt;&gt; fear
</pre>

    <p>An additional optional parameter <i>shallow</i>=<i>True</i> speeds up the lookup process but
    doesn’t check as many synonyms. You can also use <i>verb.is_emotion()</i>,
    <i>adjective.is_emotion()</i> and <i>adverb.is_emotion()</i>.</p>
    <p> </p>
    <hr/>

    <p><a id="WordNet" name="WordNet" title="WordNet"></a></p>
    <h2>WordNet glossary, synonyms, antonyms, components</h2>

    <p>WordNet describes semantic relations between synonym sets.</p>
    <p>The <i>noun.gloss()</i> command returns the dictionary description of a word:</p>
<pre>print en.noun.gloss("book")
&gt;&gt;&gt; a written work or composition that has been published (printed on pages 
&gt;&gt;&gt; bound together); "I am reading a good book on economics"
</pre>

    <p>A word can have multiple senses, for example ‘tree’ can mean a tree in a forest but also a
    tree diagram, or a person named Sir Herbert Beerbohm Tree:</p>
<pre>print en.noun.senses("tree")
&gt;&gt;&gt; [['tree'], ['tree', 'tree diagram'], ['Tree', 'Sir Beerbohm Tree']]
</pre>
<pre>print en.noun.gloss("tree", sense=1)
&gt;&gt;&gt; a figure that branches from a single root; "genealogical tree"
</pre>

    <p>The <i>noun.lexname()</i> command returns a categorization for the given word:</p>
<pre>print en.noun.lexname("book")
&gt;&gt;&gt; communication
</pre>

    <p>The <i>noun.hyponym()</i> command return examples of the given word:</p>
<pre>print en.noun.hyponym("vehicle")
&gt;&gt;&gt; [['bumper car', 'Dodgem'], ['craft'], ['military vehicle'], ['rocket', 
&gt;&gt;&gt;  'projectile'], ['skibob'], ['sled', 'sledge', 'sleigh'], ['steamroller', 
&gt;&gt;&gt;  'road roller'], ['wheeled vehicle']]
</pre>
<pre>print en.noun.hyponym("tree", sense=1)
&gt;&gt;&gt; [['cladogram'], ['stemma']]
</pre>

    <p>The <i>noun.hypernym()</i> command return abstractions of the given word:</p>
<pre>print en.noun.hypernym("earth")
print en.noun.hypernym("earth", sense=1)
&gt;&gt;&gt; [['terrestrial planet']]
&gt;&gt;&gt; [['material', 'stuff']]
</pre>

    <p>You can also execute a deep query on hypernyms and hyponyms. Notice how returned values
    become more and more abstract:</p>
<pre>print en.noun.hypernyms("vehicle", sense=0)
&gt;&gt;&gt; [['vehicle'], ['conveyance', 'transport'], 
&gt;&gt;&gt;  ['instrumentality', 'instrumentation'], 
&gt;&gt;&gt;  ['artifact', 'artefact'], ['whole', 'unit'], 
&gt;&gt;&gt;  ['object', 'physical object'], 
&gt;&gt;&gt;  ['physical entity'], ['entity']]
</pre>

    <p>The <i>noun.holonym()</i> command returns components of the given word:</p>
<pre>print en.noun.holonym("computer")
&gt;&gt;&gt; [['busbar', 'bus'], ['cathode-ray tube', 'CRT'], 
&gt;&gt;&gt;  ['central processing unit', 'CPU', 'C.P.U.', 'central processor', 
&gt;&gt;&gt;   'processor', 'mainframe'] ...
</pre>

    <p>The <i>noun.meronym()</i> command returns the collection in which the given word can be
    found:</p>
<pre>print en.noun.meronym("tree")
&gt;&gt;&gt; [['forest', 'wood', 'woods']]
</pre>

    <p>The <i>noun.antonym()</i> returns the semantic opposite of the word:</p>
<pre>print en.noun.antonym("black")
&gt;&gt;&gt; [['white', 'whiteness']]
</pre>

    <p>Find out what two words have in common:</p>
<pre>print en.noun.meet("cat", "dog", sense1=0, sense2=0)
&gt;&gt;&gt; [['carnivore']]
</pre>

    <p>The <i>noun.absurd_gloss()</i> returns an absurd description for the word:</p>
<pre>print en.noun.absurd_gloss("typography")
&gt;&gt;&gt; a business deal on a trivial scale
</pre>

    <p>The return value of a WordNet command is usually a list containing other lists of related
    words. You can use the <i>en.list.flatten()</i> command to flatten the list:</p>
<pre>print en.list.flatten(en.noun.senses("tree"))
&gt;&gt;&gt; ['tree', 'tree', 'tree diagram', 'Tree', 'Sir Herbert Beerbohm Tree']
</pre>

    <p>If you want a list of all nouns/verbs/adjectives/adverbs there’s the
    <i>wordnet.all_nouns()</i>, <i>wordnet.all_verbs()</i> ... commands:</p>
<pre>print len(en.wordnet.all_nouns())
&gt;&gt;&gt; 117096
</pre>

    <p>All of the commands shown here for nouns are also available for verbs, adjectives and
    adverbs, <i>en.verb.hypernyms(’run’)</i>, <i>en.adjective.gloss(’beautiful’)</i> etc. are valid
    commands.</p>
    <p> </p>
    <hr/>

    <p><a id="verb_conjugation" name="verb_conjugation" title="verb_conjugation"></a></p>
    <h2>Verb conjugation</h2>

    <p>PlotDevice English Linguistics knows the verb tenses for about 10000 English verbs.</p>
    <p>The <i>verb.infinitive()</i> command returns the infinitive form of a verb:</p>
<pre>print en.verb.infinitive("swimming")
&gt;&gt;&gt; swim
</pre>

    <p>The <i>verb.present()</i> command returns the present tense for the given person. Known
    values for <i>person</i> are 1, 2, 3, ‘1st’, ‘2nd’, ‘3rd’, ‘plural’, ‘*’. Just use the one you
    like most.</p>
<pre>print en.verb.present("gave")
print en.verb.present("gave", person=3, negate=False)
&gt;&gt;&gt; give
&gt;&gt;&gt; gives
</pre>

    <p>The <i>verb.present_participle()</i> command returns the present participle tense:</p>
<pre>print en.verb.present_participle("be")
&gt;&gt;&gt; being
</pre>

    <p>Return the past tense:</p>
<pre>print en.verb.past("give")
print en.verb.past("be", person=1, negate=True)
&gt;&gt;&gt; gave
&gt;&gt;&gt; wasn't
</pre>

    <p>Return the past participle tense:</p>
<pre>print en.verb.past_participle("be")
&gt;&gt;&gt; been
</pre>

    <p>A list of all possible tenses:</p>
<pre>print en.verb.tenses()
&gt;&gt;&gt; ['past', '3rd singular present', 'past participle', 'infinitive', 
&gt;&gt;&gt;  'present participle', '1st singular present', '1st singular past', 
&gt;&gt;&gt;  'past plural', '2nd singular present', '2nd singular past', 
&gt;&gt;&gt;  '3rd singular past', 'present plural']
</pre>

    <p>The <i>verb.tense()</i> command returns the tense of the given verb:</p>
<pre>print en.verb.tense("was")
&gt;&gt;&gt; 1st singular past
</pre>

    <p>Return <i>True</i> if the given verb is in the given tense:</p>
<pre>print en.verb.is_tense("wasn't", "1st singular past", negated=True)
print en.verb.is_present("does", person=1)
print en.verb.is_present_participle("doing")
print en.verb.is_past_participle("done")
&gt;&gt;&gt; True
&gt;&gt;&gt; False
&gt;&gt;&gt; True
&gt;&gt;&gt; True
</pre>

    <p>The verb.is_tense() command also accepts shorthand aliases for tenses: <i>inf</i>,
    <i>1sgpres</i>, <i>2gpres</i>, <i>3sgpres</i>, <i>pl</i>, <i>prog</i>, <i>1sgpast</i>,
    <i>2sgpast</i>, <i>3sgpast</i>, <i>pastpl</i> and <i>ppart</i>.</p>
    <hr/>

    <h2><a id="spelling" name="spelling" title="spelling"></a>Spelling corrections</h2>

    <p>PlotDevice English Linguistics is able to perform spelling corrections based on Peter Norvig’s
    algorithm. The spelling corrector has an accuracy of about 70%.</p>
    <p>The <i>spelling.suggest()</i> returns a list of possible corrections for a given word. The
    <i>spelling.correct()</i> command returns the corrected version (best guess) of the word.</p>
<pre>print en.spelling.suggest("comptuer")
&gt;&gt;&gt; ['computer']
</pre>    
    <hr/>

    <p><a id="shallow_parsing" name="shallow_parsing" title="shallow_parsing"></a></p>
    <h2>Shallow parsing, the grammatical structure of a sentence</h2>

    <p>PlotDevice English Linguistics is able to do sentence structure analysis using a combination of
    Jason Wiener’s tagger and NLTK’s chunker. The tagger assigns a part-of-speech tag to each word
    in the sentence using a (Brill’s) lexicon. A <i>postag</i> is something like NN or VBP marking
    words as nouns, verbs, determiners, pronouns, etc. The chunker is then able to group syntactic
    units in the sentence. A syntactic unit is, for example, a determiner followed by adjectives
    followed by a noun: <i>the tasty little chicken</i> is a syntactic unit.</p>
    <p>The <i>sentence.tag()</i> command tags the given sentence. The return value is a list of
    <i>(word, tag)</i> tuples. However, when you print it out it will look like a string.</p>
<pre>print en.sentence.tag("this is so cool")
&gt;&gt;&gt; this/DT is/VBZ so/RB cool/JJ
</pre>

    <p>There are lots of part-of-speech tags and it takes some time getting to know them. The full
    list is <a href="Linguistics/part_of_speech_tags.html">here</a>. The
    <i>sentence.tag_description()</i> returns a <i>(description, examples)</i> tuple for a given
    tag:</p>
<pre>print en.sentence.tag_description("NN")
&gt;&gt;&gt; ('noun, singular or mass', 'tiger, chair, laughter')
</pre>

    <p>The <i>sentence.chunk()</i> command returns the chunked sentence:</p>
<pre>from pprint import pprint
pprint( en.sentence.chunk("we are going to school") )
&gt;&gt;&gt; [['SP',
&gt;&gt;&gt;   ['NP', ('we', 'PRP')],
&gt;&gt;&gt;   ['AP',
&gt;&gt;&gt;   ['VP', ('are', 'VBP'), ('going', 'VBG'), ('to', 'TO')],
&gt;&gt;&gt;   ['NP', ('school', 'NN')]]]]
</pre>

    <p>Now what does all this mean?</p>
    <ul>
      <li><b>NP</b>: noun phrases, syntactic units describing a noun, for example: a big fish.
      </li><li><b>VP</b>: verb phrases, units of verbs and auxillaries, for example: are going to.
      </li><li><b>AP</b>: a verb/argument structure, a verb phrase and a noun phrase being influenced.
      </li><li><b>SP</b>: a subject structure: a noun phrase which is the executor of a verb phrase or
      verb/argument structure.
    </li></ul>

    <p>A handy <i>sentence.traverse(sentence, cmd)</i> command lets you feed a chunked sentence to
    your own command chunk by chunk:</p>
<pre>s = "we are going to school"
def callback(chunk, token, tag):
    if chunk != None : 
        print en.sentence.tag_description(chunk)[0].upper()
    if chunk == None : 
        print token, "("+en.sentence.tag_description(tag)[0]+")"
en.sentence.traverse(s, callback)
&gt;&gt;&gt; SUBJECT PHRASE
&gt;&gt;&gt; NOUN PHRASE
&gt;&gt;&gt; we (pronoun, personal)
&gt;&gt;&gt; VERB PHRASE AND ARGUMENTS
&gt;&gt;&gt; VERB PHRASE
&gt;&gt;&gt; are (verb, non-3rd person singular present)
&gt;&gt;&gt; going (verb, gerund or present participle)
&gt;&gt;&gt; to (infinitival to)
&gt;&gt;&gt; NOUN PHRASE
&gt;&gt;&gt; school (noun, singular or mass)
</pre>

    <p>A even handier <i>sentence.find(sentence, pattern)</i> command lets you find patterns of
    text in a sentence:</p>
<pre>s = "The world is full of strange and mysterious things."
print en.sentence.find(s, "JJ and JJ NN")
&gt;&gt;&gt; [[('strange', 'JJ'), ('and', 'CC'), 
&gt;&gt;&gt;   ('mysterious', 'JJ'), ('things', 'NNS')]]
</pre>

    <p>The returned list contains all chunks of text that matched the pattern. In the example above
    it retrieved all chunks of the form <i>an adjective + and + an adjective + a noun</i>. Notice
    that when you use something like ‘NN’ in your pattern (noun), NNS (plural nouns) are returned
    as well.</p>
<pre>s = "The hairy hamsters visited the cruel dentist."
matches = en.sentence.find(s, "JJ NN")
print matches
&gt;&gt;&gt; [[('hairy', 'JJ'), ('hamsters', 'NNS')], 
     [('cruel', 'JJ'), ('dentist', 'NN')]]
</pre>

    <p>An optional <i>chunked</i> parameter can be set to <i>False</i> to return strings instead of
    token/tag tuples. You can put pieces of the pattern between brackets to make them optional, or
    use wildcards:</p>
<pre>s = "This makes the parser an extremely powerful tool."
print en.sentence.find(s, "(extreme*) (JJ) NN", chunked=False)
&gt;&gt;&gt; ['parser', 'extremely powerful tool']
</pre>

    <p>Finally, if you feel up to it you could feed the following command with a list of your own
    regular expression units to chunk, mine are pretty basic as I’m not a linguist.</p>
<pre>print en.sentence.chunk_rules()
</pre>

    <p> </p>
    <hr/>

    <p><a id="summarisation" name="summarisation" title="summarisation"></a></p>
    <h2>Summarisation of text to keywords</h2>

    <p>PlotDevice English Linguistics is able to strip keywords from a given text.</p>
<pre>en.content.keywords(txt, top=10, nouns=True, singularize=True, filters=[])
</pre>

    <p>The <i>content.keywords()</i> command guesses a list of words that frequently occur in the
    given text. The return value is a list (length defined by top) of <i>(count, word)</i> tuples.
    When <i>nouns</i> is <i>True</i>, returns only nouns. The command furthermore ignores
    connectives, numbers and tags. When <i>singularize</i> is <i>True</i>, attempts to singularize
    nouns in the text. The optional <i>filters</i> parameter is a list of words which the command
    should ignore.</p>
    <p>So, assuming you would want to summarise web content you can do the following:</p>
<pre>from urllib import urlopen
html = urlopen("http://news.bbc.co.uk/").read()
meta = ["news", "health", "uk", "version", "weather", 
        "video", "sport", "return", "read", "help"]
print sentence_keywords(html, filters=meta)
&gt;&gt;&gt; [(6, 'funeral'), (5, 'beirut'), (3, 'war'), (3, 'service'), (3, 'radio'), 
&gt;&gt;&gt;  (3, 'lebanon'), (3, 'islamist'), (3, 'function'), (3, 'female')]
</pre>

    <p> </p>
    <hr/>

    <h2><a id="rid" name="rid" title="rid"></a>Regressive Imagery Dictionary, psychological content
    analysis</h2>

    <p>PlotDevice English Linguistics is able to do psychological content analysis using John
    Wiseman’s Python implementation of the Regressive Imagery Dictionary. The RID asigns scores to
    <i>primary</i>, <i>secondary</i> and <i>emotional</i> process thoughts in a text.</p>
    <ul>
      <li>Primary: free-form associative thinking involved in dreams and fantasy
      </li><li>Secondary: logical, reality-based and focused on problem solving
      </li><li>Emotions: expressions of fear, sadness, hate, affection, etc.
    </li></ul>
<pre>en.content.categorise(str)
</pre>

    <p>The <i>content.categorise()</i> command returns a sorted list of categories found in the
    text. Each item in the list has the following properties:</p>
    <ul>
      <li><i>item.name</i>: the name of the category
      </li><li><i>item.count</i>: the number of words in the text that fall into this category
      </li><li><i>item.words</i>: a list of words from the text that fall into this category
      </li><li><i>item.type</i>: the type of category, either ‘primary’, ‘secondary’ or ‘emotions’.
    </li></ul>

    <p>Let’s run a little test with Lucas’ <a href="Keywords/Ideas_from_the_Heart.html">Ideas from
    the Heart</a> text:<br/></p>
<pre>txt = open("heart.txt").read()
summary = en.content.categorise(txt)
print summary.primary
print summary.secondary
print summary.emotions
&gt;&gt;&gt; 0.290155440415
&gt;&gt;&gt; 0.637305699482
&gt;&gt;&gt; 0.0725388601036
# Lucas' text has a 64% secondary value.
</pre>
<pre># The top 5 categories in the text:
for category in summary[:5]:
    print category.name, category.count
&gt;&gt;&gt; instrumental behavior 30
&gt;&gt;&gt; abstraction 30
&gt;&gt;&gt; social behavior 28
&gt;&gt;&gt; temporal references 24
&gt;&gt;&gt; concreteness 18
</pre>
<pre># Words in the top "instrumental behavior" category:
print summary[0].words
&gt;&gt;&gt; ['students', 'make', 'students', 'reached', 'countless', 
&gt;&gt;&gt;  'student', 'workshop', 'workshop', 'students', 'finish', 
&gt;&gt;&gt;  'spent', 'produce', 'using', 'work', 'students', 'successful', 
&gt;&gt;&gt;  'workshop', 'students', 'pursue', 'skills', 'use', 
&gt;&gt;&gt;  'craftsmanship', 'use', 'using', 'workshops', 'workshops', 
&gt;&gt;&gt;  'result', 'students', 'workshops', 'student']
</pre>

    <p>You can find all the categories for primary, secondary and emotional scores in the
    <i>en.rid.primary</i>, <i>en.rid.secondary</i> and <i>en.rid.emotions</i> lists.</p>
    <p> </p>
    <p> </p>
    <hr size="2" width="100%"/>

    <p> </p>
    <h2><a id="ogden" name="ogden" title="ogden"></a>Ogden’s basic English words</h2>

    <p>PlotDevice English Linguistics comes bundled with Charles K. Ogden list of basic English words:
    a set of 2000 words that can express 90% of the concepts in English. The list is stored as
    <i>en.basic.words</i>. It can be filtered for <i>nouns</i>, <i>verbs</i>, <i>adjectives</i> and
    <i>adverbs</i>:</p>
<pre>print en.basic.words
&gt;&gt;&gt; ['a', 'able', 'about', 'account', 'acid', 'across', ... ]
</pre>
<pre>print en.basic.verbs
&gt;&gt;&gt; ['account', 'act', 'air', 'amount', 'angle', 'answer', ... ]
</pre><br/>
  </div>

</body></html>